# HeyMake ğŸ¬

Plataforma de generaciÃ³n de trailers con IA - Transforma guiones en trailers visuales usando modelos de IA de Ãºltima generaciÃ³n.

## ğŸš€ Features

- **AnÃ¡lisis de Guiones**: Convierte scripts en escenas estructuradas usando LLM
- **GeneraciÃ³n de ImÃ¡genes**: MÃºltiples proveedores (Gemini, Higgsfield, DALL-E, AIMLAPI)
- **AnimaciÃ³n de Videos**: Convierte imÃ¡genes en videos con Kling AI y Google Veo
- **Streaming en Tiempo Real**: Progress tracking con Server-Sent Events
- **Reference Prompts**: Sistema de prompts de referencia para consistencia visual

## ğŸ›  Tech Stack

### Backend
- **FastAPI** (Python 3.12) - API REST
- **Turso** (LibSQL) - Base de datos
- **Redis** - Cache y sessions
- **Multiple AI APIs**:
  - OpenAI GPT-4 (LLM + DALL-E)
  - Google Gemini (LLM + Imagen)
  - Higgsfield (Flux)
  - AIMLAPI (Flux + otros modelos)
  - Kling AI (Video)
  - Google Veo (Video)

### Frontend
- **Next.js 14** - React framework
- **TypeScript** - Type safety
- **Tailwind CSS** - Styling
- **Server-Sent Events** - Real-time updates

## ğŸ“ Estructura del Proyecto

```
heyai/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/         # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/           # ConfiguraciÃ³n
â”‚   â”‚   â”œâ”€â”€ schemas/        # Pydantic models
â”‚   â”‚   â””â”€â”€ services/       # Business logic
â”‚   â”œâ”€â”€ main.py             # Entry point
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # Next.js frontend
â”‚   â”œâ”€â”€ src/app/           # App router
â”‚   â”œâ”€â”€ public/            # Static assets
â”‚   â””â”€â”€ package.json       # Node dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Setup Local

### Prerequisites

- Python 3.12+
- Node.js 18+
- Redis server
- API keys (ver Variables de Entorno)

### 1. Clonar repositorio

```bash
git clone https://github.com/diegoparma/heymake.git
cd heymake
```

### 2. Backend Setup

```bash
cd backend

# Crear virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus API keys

# Ejecutar
python main.py
```

Backend corriendo en: http://localhost:8000

### 3. Frontend Setup

```bash
cd frontend

# Instalar dependencias
npm install

# Ejecutar en desarrollo
npm run dev
```

Frontend corriendo en: http://localhost:3000

## ğŸ”‘ Variables de Entorno

Crear archivo `backend/.env` con estas variables:

```env
# App
SECRET_KEY="your-secret-key-here"
ENV="development"

# Database - Turso
DATABASE_URL="your-turso-database-url"
DATABASE_AUTH_TOKEN="your-turso-auth-token"

# Redis
REDIS_URL="redis://localhost:6379"

# LLM Services
OPENAI_API_KEY="your-openai-key"
GOOGLE_AI_API_KEY="your-google-ai-key"
LLM_PROVIDER="openai"
LLM_MODEL="gpt-4-turbo-preview"

# Image Generation
HIGGSFIELD_API_KEY_ID="your-higgsfield-id"
HIGGSFIELD_API_KEY_SECRET="your-higgsfield-secret"
HIGGSFIELD_API_URL="https://platform.higgsfield.ai"

# Video Generation
KLING_API_KEY="your-kling-key"

# Storage
GOOGLE_DRIVE_CREDENTIALS_FILE="credentials.json"
```

### Donde conseguir API Keys:

- **OpenAI**: https://platform.openai.com/api-keys
- **Google AI**: https://aistudio.google.com/app/apikey
- **Higgsfield**: https://cloud.higgsfield.ai (requiere crÃ©ditos)
- **Kling AI**: https://klingai.com/

## ğŸš€ Deployment

### OpciÃ³n 1: Vercel (Frontend) + Render (Backend)

#### Frontend en Vercel:
1. Push cÃ³digo a GitHub
2. Conectar repositorio en Vercel
3. Configurar build:
   ```
   Framework: Next.js
   Root Directory: frontend
   Build Command: npm run build
   Output Directory: .next
   ```

#### Backend en Render:
1. Crear Web Service en Render
2. Conectar repositorio GitHub
3. Configurar:
   ```
   Environment: Python 3
   Root Directory: backend
   Build Command: pip install -r requirements.txt
   Start Command: python main.py
   ```
4. Agregar variables de entorno en Render dashboard

### OpciÃ³n 2: Todo en Render

Ver `render.yaml` para configuraciÃ³n completa.

## ğŸ“š API Documentation

Una vez ejecutando, la documentaciÃ³n interactiva estÃ¡ disponible en:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Endpoints principales:

- `POST /api/v1/generation/analyze-script` - Analizar guiÃ³n
- `GET /api/v1/generation/generate-images-stream/{project_id}` - Generar imÃ¡genes (SSE)
- `POST /api/v1/generation/animate-scene` - Animar escena individual

## ğŸ› Troubleshooting

### Backend no inicia
- Verificar que Redis estÃ© corriendo
- Revisar API keys en `.env`
- Verificar versiÃ³n de Python (3.12+)

### Frontend no conecta con Backend
- Verificar que backend estÃ© en puerto 8000
- Revisar configuraciÃ³n de CORS en `main.py`

### Errores de generaciÃ³n
- Verificar crÃ©ditos en APIs (Higgsfield)
- Revisar quotas (Google AI)
- Ver logs en `/tmp/backend.log`

## ğŸ”’ Security Notes

- **Nunca** commitir archivos `.env` con API keys
- Rotar API keys regularmente
- Usar variables de entorno en producciÃ³n
- Implementar autenticaciÃ³n antes de producciÃ³n

## ğŸ“ˆ Performance

- Redis para caching (no implementado aÃºn)
- OptimizaciÃ³n de imÃ¡genes con Pillow
- CompresiÃ³n de assets estÃ¡ticos
- Rate limiting en endpoints crÃ­ticos

## ğŸ¤ Contributing

1. Fork el repositorio
2. Crear feature branch (`git checkout -b feature/amazing-feature`)
3. Commit cambios (`git commit -m 'Add some amazing feature'`)
4. Push a la branch (`git push origin feature/amazing-feature`)
5. Abrir Pull Request

## ğŸ“„ License

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ“ Support

Si encontrÃ¡s problemas o tenÃ©s preguntas:

1. Revisar [Issues existentes](https://github.com/diegoparma/heymake/issues)
2. Crear un [nuevo Issue](https://github.com/diegoparma/heymake/issues/new)
3. Incluir logs y configuraciÃ³n (sin API keys)

---

Hecho con â¤ï¸ usando FastAPI y Next.js
cp .env.example .env.local
# Configurar variables de entorno
npm run dev
```

## ğŸ”§ ConfiguraciÃ³n

### 1. Turso Database
Ver guÃ­a detallada: [docs/TURSO_SETUP.md](docs/TURSO_SETUP.md)

```bash
# Instalar CLI
curl -sSfL https://get.tur.so/install.sh | bash

# Crear database
turso db create heyai
turso db tokens create heyai
```

### 2. Google Drive API
Ver guÃ­a detallada: [docs/GOOGLE_DRIVE_SETUP.md](docs/GOOGLE_DRIVE_SETUP.md)
x] v0.1: Backend base + integraciÃ³n LLM
- [x] v0.2: IntegraciÃ³n Higgsfield para imÃ¡genes
- [x] v0.3: IntegraciÃ³n Kling para animaciÃ³n
- [x] v0.4: Google Drive storage
- [ ] v0.5: Frontend bÃ¡sico
- [ ] v0.6: Sistema completo de generaciÃ³n
- [ ] v0.7: Workflow de aprobaciÃ³n
- [ ] v1.0: Release inicial
- [ ] v2.0: Ensamblaje automÃ¡tico (opcional)
### 3. API Keys
- **OpenAI/Anthropic**: Para anÃ¡lisis de guiones
- **Higgsfield**: Para generaciÃ³n de imÃ¡genes
- **Kling/Runway**: Para animaciÃ³n de videos

Ver [docs/KLING_SETUP.md](docs/KLING_SETUP.md) para alternativas.

## ğŸ“– DocumentaciÃ³n

Ver [docs/](./docs) para documentaciÃ³n detallada.

## ğŸ¯ Roadmap

- [ ] v0.1: Backend base + integraciÃ³n LLM
- [ ] v0.2: IntegraciÃ³n Higgsfield
- [ ] v0.3: Frontend bÃ¡sico
- [ ] v0.4: Procesamiento de video
- [ ] v0.5: Sistema completo de assets
- [ ] v1.0: Release inicial

## ğŸ“ Licencia

MIT
